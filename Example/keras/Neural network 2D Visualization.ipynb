{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, PReLU, Input, Embedding, Lambda\n",
    "from keras.optimizers import Adam\n",
    "import NnVisualizer\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Softmax loss with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# X shape (60,000 28x28), y shape (10,000, )\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],  1) / 255.   # normalize\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1) / 255.      # normalize\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)    #one hot\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "nn_input = Input(shape=(28, 28, 1))\n",
    "nn = Conv2D(32, (3, 3))(nn_input)\n",
    "nn = PReLU()(nn)\n",
    "nn = Conv2D(32, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = MaxPooling2D()(nn)\n",
    "nn = Conv2D(64, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = Conv2D(64, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = MaxPooling2D()(nn)\n",
    "nn = Flatten()(nn)\n",
    "nn = Dense(2)(nn)\n",
    "nn = PReLU(name = 'visualize_layer')(nn)\n",
    "nn = Dense(10, activation = 'softmax')(nn)\n",
    "model = Model(inputs = nn_input, outputs = nn)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training ------------')\n",
    "visualize_callback = NnVisualizer.Histories()\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=32, validation_data=([x_test, y_test]), callbacks=[visualize_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center loss with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train_label), (x_test, y_test_label) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],  1) / 255.   # normalize\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1) / 255.      # normalize\n",
    "y_train = np_utils.to_categorical(y_train_label, num_classes=10)    #one hot\n",
    "y_test = np_utils.to_categorical(y_test_label, num_classes=10)    #one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create softmax model\n",
    "nn_input = Input(shape=(28, 28, 1))\n",
    "nn = Conv2D(32, (3, 3))(nn_input)\n",
    "nn = PReLU()(nn)\n",
    "nn = Conv2D(32, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = MaxPooling2D()(nn)\n",
    "nn = Conv2D(64, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = Conv2D(64, (3, 3))(nn)\n",
    "nn = PReLU()(nn)\n",
    "nn = MaxPooling2D()(nn)\n",
    "nn = Flatten()(nn)\n",
    "nn = Dense(2)(nn)\n",
    "visualize_feature = PReLU(name = 'visualize_layer')(nn)\n",
    "nn = Dense(10, activation = 'softmax')(visualize_feature)\n",
    "model = Model(inputs = nn_input, outputs = nn)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dum of square error lambda\n",
    "l2 = lambda x: np.sum((x[0] - x[1])**2, keepdims = True)\n",
    "\n",
    "# Create prior model (center loss)\n",
    "prior_nn_input = Input(shape=(1,))   # single value ground truth labels as inputs\n",
    "centers = Embedding(10, 2)(prior_nn_input)  # Computer center\n",
    "centers = Flatten()(centers)  # visualize_feature.shape = (?, 2) centers.shape = (?, 1, 2)\n",
    "lc = Lambda(l2, name = 'lc')([visualize_feature, centers])\n",
    "prior_model = Model(inputs=[nn_input, prior_nn_input], outputs=[nn, lc])\n",
    "\n",
    "prior_model.compile(optimizer=Adam(), \n",
    "                    loss=[\"categorical_crossentropy\", lambda true, pred: pred],\n",
    "                    loss_weights=[1, 0.2], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NnVisualizer\n",
    "print('Training ------------')\n",
    "visualize_callback = NnVisualizer.Histories(True)\n",
    "random_y_train = np.random.rand(x_train.shape[0], 1)\n",
    "random_y_test = np.random.rand(x_test.shape[0], 1)\n",
    "\n",
    "prior_model.fit([x_train, y_train_label], [y_train, random_y_train], epochs=2, batch_size=32, validation_data=([x_test, y_test_label], [y_test, random_y_test]), callbacks=[visualize_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
